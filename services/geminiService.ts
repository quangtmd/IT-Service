
// Fix: Import correct types from @google/genai
import { GoogleGenAI, Chat, GenerateContentResponse, Part, Content, Type, FunctionDeclaration } from "@google/genai"; // Added Part, Content, Type, FunctionDeclaration
import * as Constants from '../constants.tsx';
// Fix: Added SiteSettings, Article, Product
import { AIBuildResponse, ChatMessage, GroundingChunk, SiteSettings, Article, Product, AIBuildSuggestionsResponse } from "../types"; 
import { MOCK_SERVICES } from '../data/mockData';
// FIX: Import PRODUCT_CATEGORIES_HIERARCHY from constants
import { PRODUCT_CATEGORIES_HIERARCHY } from '../constants.tsx';


const CHAT_MODEL_NAME = 'gemini-2.5-flash';
const BUILDER_MODEL_NAME = 'gemini-2.5-flash';
const IMAGE_MODEL_NAME = 'imagen-4.0-generate-001';

let aiInstance: GoogleGenAI | null = null;
let chatSessionInstance: Chat | null = null; // Renamed to avoid conflict with 'Chat' type

const getAiClient = (): GoogleGenAI | null => {
  // Fix: Use process.env.API_KEY as per guidelines to resolve TypeScript error.
  const apiKey = process.env.API_KEY;
  // This robust check handles both missing keys and the 'undefined' string issue from some build tools.
  if (!apiKey || apiKey === 'undefined') {
    if (!aiInstance) { // Log this warning only once to avoid spamming the console
        // Fix: Update warning message to reflect the correct environment variable.
        console.warn("Gemini Service: API_KEY is not configured. AI features will be disabled.");
    }
    return null;
  }

  if (!aiInstance) {
    aiInstance = new GoogleGenAI({ apiKey: apiKey as string });
  }
  return aiInstance;
};

const getOrderStatusFunctionDeclaration: FunctionDeclaration = {
  name: 'getOrderStatus',
  parameters: {
    type: Type.OBJECT,
    description: 'T√¨m ki·∫øm v√† l·∫•y th√¥ng tin chi ti·∫øt ƒë∆°n h√†ng. C·∫ßn thi·∫øt khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ tr·∫°ng th√°i, v·ªã tr√≠ ƒë∆°n h√†ng, ho·∫∑c l·ªãch s·ª≠ mua h√†ng.',
    properties: {
      orderId: {
        type: Type.STRING,
        description: 'M√£ ƒë∆°n h√†ng ho·∫∑c t·ª´ kh√≥a ƒë·ªãnh danh ƒë∆°n h√†ng m√† ng∆∞·ªùi d√πng cung c·∫•p (VD: "12345", "dh-123", "T123"). N·∫øu kh√¥ng r√µ, h√£y l·∫•y to√†n b·ªô chu·ªói s·ªë/m√£ m√† ng∆∞·ªùi d√πng ƒë∆∞a ra.',
      },
    },
    required: ['orderId'],
  },
};


// Fix: Change history type from GenerateContentParameters[] to Content[]
export const startChat = (
  siteSettings: SiteSettings, // Added siteSettings
  history?: Content[], 
  systemInstructionOverride?: string
): Chat => {
  const client = getAiClient();
  if (!client) {
      throw new Error(Constants.API_KEY_ERROR_MESSAGE);
  }

  let socialLinksInfo = "";
  if (siteSettings.socialFacebookUrl) socialLinksInfo += `\n- Facebook: ${siteSettings.socialFacebookUrl}`;
  if (siteSettings.socialZaloUrl) socialLinksInfo += `\n- Zalo: ${siteSettings.socialZaloUrl}`;
  if (siteSettings.socialYoutubeUrl) socialLinksInfo += `\n- YouTube: ${siteSettings.socialYoutubeUrl}`;

  const serviceInfo = MOCK_SERVICES.map(service => 
    `- D·ªãch v·ª•: ${service.name}\n  M√¥ t·∫£: ${service.description}\n  Link chi ti·∫øt: ${window.location.origin}${window.location.pathname}#/service/${service.slug || service.id}`
  ).join('\n\n');

  const productCategoriesInfo = PRODUCT_CATEGORIES_HIERARCHY
    .map(cat => `- ${cat.name}`)
    .join('\n');


  const defaultSystemInstruction = `B·∫°n l√† tr·ª£ l√Ω AI c·ªßa ${siteSettings.companyName}.

**NHI·ªÜM V·ª§ CH√çNH:**
B·∫°n l√† m·ªôt nh√¢n vi√™n t∆∞ v·∫•n nhi·ªát t√¨nh, am hi·ªÉu c√¥ng ngh·ªá. Nhi·ªám v·ª• c·ªßa b·∫°n l√† h·ªó tr·ª£ kh√°ch h√†ng b·∫±ng **Ti·∫øng Vi·ªát**.

**NGUY√äN T·∫ÆC PH·∫¢N H·ªíI:**
1.  **Lu√¥n s·ª≠ d·ª•ng Ti·∫øng Vi·ªát:** K·ªÉ c·∫£ khi kh√°ch h√†ng h·ªèi b·∫±ng ti·∫øng Anh ho·∫∑c ng√¥n ng·ªØ kh√°c, h√£y tr·∫£ l·ªùi l·∫°i b·∫±ng Ti·∫øng Vi·ªát m·ªôt c√°ch l·ªãch s·ª± (tr·ª´ khi h·ªç y√™u c·∫ßu c·ª• th·ªÉ kh√°c).
2.  **Th√¢n thi·ªán & Chuy√™n nghi·ªáp:** D√πng t·ª´ ng·ªØ t·ª± nhi√™n, c√≥ th·ªÉ d√πng emoji nh·∫π nh√†ng üòä.
3.  **Ng·∫Øn g·ªçn & ƒêi th·∫≥ng v√†o v·∫•n ƒë·ªÅ:** Tr√°nh vi·∫øt qu√° d√†i d√≤ng.

**NHI·ªÜM V·ª§ C·ª§ TH·ªÇ:**
- **Tra c·ª©u ƒë∆°n h√†ng:** Kh√°ch h√†ng th∆∞·ªùng h·ªèi v·ªÅ ƒë∆°n h√†ng b·∫±ng m√£ s·ªë (v√≠ d·ª•: "ƒë∆°n 123", "check ƒë∆°n h√†ng T456"). H√£y ∆ØU TI√äN g·ªçi h√†m \`getOrderStatus(orderId: "...")\` khi th·∫•y m√£ s·ªë.
- **T∆∞ v·∫•n s·∫£n ph·∫©m:** D·ª±a v√†o danh m·ª•c s·∫£n ph·∫©m b√™n d∆∞·ªõi ƒë·ªÉ g·ª£i √Ω. N·∫øu kh√°ch h·ªèi chi ti·∫øt gi√°/kho, h√£y h∆∞·ªõng d·∫´n xem tr√™n website.
- **T∆∞ v·∫•n c·∫•u h√¨nh PC:** ƒê∆∞a ra l·ªùi khuy√™n c∆° b·∫£n v·ªÅ ch·ªçn linh ki·ªán ph√π h·ª£p nhu c·∫ßu.

**TH√îNG TIN C·ª¨A H√ÄNG:**
- Danh m·ª•c s·∫£n ph·∫©m:
${productCategoriesInfo}

- D·ªãch v·ª• IT:
${serviceInfo}

- Li√™n h·ªá:
  - Hotline: ${siteSettings.companyPhone}
  - Email: ${siteSettings.companyEmail}
  - ƒê·ªãa ch·ªâ: ${siteSettings.companyAddress}
${socialLinksInfo}

**L∆∞u √Ω:** Khi cung c·∫•p link, s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng Markdown: [T√™n Link](URL).`;

  chatSessionInstance = client.chats.create({
    model: CHAT_MODEL_NAME,
    history: history || [],
    config: {
      systemInstruction: systemInstructionOverride || defaultSystemInstruction,
      tools: [{functionDeclarations: [getOrderStatusFunctionDeclaration]}],
    },
  });
  return chatSessionInstance;
};

export const sendMessageToChatStream = async (
  message: string,
  currentChatInstance?: Chat
// Fix: Change GenerateContentStreamResult to AsyncIterable<GenerateContentResponse>
): Promise<AsyncIterable<GenerateContentResponse>> => {
  const chatToUse = currentChatInstance || chatSessionInstance;
  if (!chatToUse) {
    throw new Error("Chat not initialized. Call startChat first.");
  }
  
  const client = getAiClient();
  if (!client) {
      throw new Error(Constants.API_KEY_ERROR_MESSAGE);
  }

  try {
    return await chatToUse.sendMessageStream({ message });
  } catch (error) {
    console.error("Error sending message to Gemini (stream):", error);
    throw error;
  }
};

export const generatePCBuildRecommendation = async (
  useCase: string,
  budget: string,
  currentComponents?: Record<string, string>
): Promise<AIBuildResponse> => {
  const client = getAiClient(); 
  if (!client) {
      throw new Error(Constants.API_KEY_ERROR_MESSAGE);
  }

  let prompt = `T√¥i c·∫ßn x√¢y d·ª±ng m·ªôt c·∫•u h√¨nh PC.
Nhu c·∫ßu s·ª≠ d·ª•ng: ${useCase}.
Ng√¢n s√°ch: ${budget}.`;

  if (currentComponents && Object.keys(currentComponents).length > 0) {
    prompt += "\nC√°c linh ki·ªán ƒë√£ c√≥ ho·∫∑c ∆∞u ti√™n:";
    for (const [key, value] of Object.entries(currentComponents)) {
      if (value) prompt += `\n- ${key}: ${value}`;
    }
  }

  prompt += `\nH√£y ƒë·ªÅ xu·∫•t m·ªôt c·∫•u h√¨nh PC t∆∞∆°ng th√≠ch bao g·ªìm CPU, Bo m·∫°ch ch·ªß (Motherboard), RAM (ghi r√µ dung l∆∞·ª£ng v√† t·ªëc ƒë·ªô), GPU (Card ƒë·ªì h·ªça), SSD (ghi r√µ dung l∆∞·ª£ng), PSU (Ngu·ªìn - ghi r√µ c√¥ng su·∫•t), v√† V·ªè m√°y (Case).
Cung c·∫•p ph·∫£n h·ªìi d∆∞·ªõi d·∫°ng m·ªôt ƒë·ªëi t∆∞·ª£ng JSON v·ªõi c√°c kh√≥a: 'cpu', 'motherboard', 'ram', 'gpu', 'ssd', 'psu', 'case'. M·ªói kh√≥a n√†y n√™n l√† m·ªôt ƒë·ªëi t∆∞·ª£ng ch·ª©a hai kh√≥a con: 'name' (t√™n linh ki·ªán c·ª• th·ªÉ) v√† 'reasoning' (l√Ω do ng·∫Øn g·ªçn ch·ªçn linh ki·ªán ƒë√≥ b·∫±ng Ti·∫øng Vi·ªát).
V√≠ d·ª•: { "cpu": { "name": "AMD Ryzen 5 5600X", "reasoning": "Hi·ªáu nƒÉng t·ªët cho gaming t·∫ßm trung." }, ... }.
N·∫øu ng√¢n s√°ch qu√° th·∫•p cho nhu c·∫ßu s·ª≠ d·ª•ng, h√£y tr·∫£ v·ªÅ JSON c√≥ d·∫°ng { "error": "Ng√¢n s√°ch qu√° th·∫•p cho nhu c·∫ßu n√†y." }.`;
  
  try {
    const response: GenerateContentResponse = await client.models.generateContent({
      model: BUILDER_MODEL_NAME,
      contents: prompt,
      config: {
        responseMimeType: "application/json",
      },
    });

    let jsonStr = response.text.trim();
    const fenceRegex = /^\`\`\`(\w*)?\s*\n?(.*?)\n?\s*\`\`\`$/s;
    const match = jsonStr.match(fenceRegex);
    if (match && match[2]) {
      jsonStr = match[2].trim();
    }
    
    return JSON.parse(jsonStr) as AIBuildResponse;

  } catch (error) {
    console.error("Error generating PC build recommendation:", error);
    if (error instanceof Error && error.message.includes("JSON")) {
         return { error: "AI ƒë√£ tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i." };
    }
    return { error: "ƒê√£ x·∫£y ra l·ªói khi nh·∫≠n ƒë·ªÅ xu·∫•t t·ª´ AI. Vui l√≤ng th·ª≠ l·∫°i." };
  }
};

export const generatePCBuildSuggestions = async (
  useCase: 'PC Gaming' | 'PC VƒÉn ph√≤ng',
  budget: string,
  additionalRequirements: string
): Promise<AIBuildSuggestionsResponse> => {
  const client = getAiClient();
  if (!client) {
      throw new Error(Constants.API_KEY_ERROR_MESSAGE);
  }

  const prompt = `B·∫°n l√† m·ªôt chuy√™n gia x√¢y d·ª±ng PC t·∫°i c·ª≠a h√†ng Vi·ªát Nam c√≥ t√™n "IQ Technology". D·ª±a tr√™n nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng, h√£y ƒë·ªÅ xu·∫•t 2-3 c·∫•u h√¨nh PC ri√™ng bi·ªát (v√≠ d·ª•: m·ªôt c·∫•u h√¨nh t·ªëi ∆∞u gi√°, m·ªôt c·∫•u h√¨nh hi·ªáu nƒÉng cao, ho·∫∑c m·ªôt d√πng Intel v√† m·ªôt d√πng AMD).

Nhu c·∫ßu c·ªßa ng∆∞·ªùi d√πng:
- M·ª•c ƒë√≠ch: ${useCase}
- Ng√¢n s√°ch: ${budget} VNƒê
- Y√™u c·∫ßu th√™m: ${additionalRequirements || 'Kh√¥ng c√≥'}

ƒê·ªëi v·ªõi m·ªói c·∫•u h√¨nh, h√£y cung c·∫•p m·ªôt t√™n g·ªçi ti·∫øng Vi·ªát (v√≠ d·ª•: "C·∫•u h√¨nh Gaming T·∫ßm trung"), m·ªôt t·ªïng gi√° ti·ªÅn ∆∞·ªõc t√≠nh (d·∫°ng s·ªë), m·ªôt l√Ω do ng·∫Øn g·ªçn ti·∫øng Vi·ªát t·∫°i sao c·∫•u h√¨nh n√†y ph√π h·ª£p, v√† danh s√°ch c√°c linh ki·ªán c·ª• th·ªÉ bao g·ªìm: CPU, GPU, RAM, Motherboard, SSD, PSU, v√† Case.
Ph·∫£n h·ªìi c·ªßa b·∫°n PH·∫¢I tu√¢n th·ªß nghi√™m ng·∫∑t theo JSON schema ƒë√£ ƒë∆∞·ª£c cung c·∫•p.`;

  const responseSchema = {
    type: Type.OBJECT,
    properties: {
      suggestions: {
        type: Type.ARRAY,
        description: "M·ªôt danh s√°ch c√°c c·∫•u h√¨nh PC ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t.",
        items: {
          type: Type.OBJECT,
          properties: {
            name: { type: Type.STRING, description: "T√™n c·ªßa c·∫•u h√¨nh, v√≠ d·ª•: C·∫•u h√¨nh Gaming T·∫ßm Trung." },
            total_price: { type: Type.NUMBER, description: "T·ªïng chi ph√≠ ∆∞·ªõc t√≠nh b·∫±ng VNƒê." },
            reasoning: { type: Type.STRING, description: "Gi·∫£i th√≠ch ng·∫Øn g·ªçn t·∫°i sao c·∫•u h√¨nh n√†y ph√π h·ª£p (Ti·∫øng Vi·ªát)." },
            components: {
              type: Type.OBJECT,
              properties: {
                CPU: { type: Type.STRING },
                GPU: { type: Type.STRING },
                RAM: { type: Type.STRING },
                Motherboard: { type: Type.STRING },
                SSD: { type: Type.STRING },
                PSU: { type: Type.STRING },
                Case: { type: Type.STRING },
              },
              required: ["CPU", "GPU", "RAM", "Motherboard", "SSD", "PSU", "Case"]
            },
          },
          required: ["name", "total_price", "reasoning", "components"]
        },
      },
    },
    required: ["suggestions"],
  };

  try {
    const response: GenerateContentResponse = await client.models.generateContent({
      model: BUILDER_MODEL_NAME,
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: responseSchema,
      },
    });

    const jsonStr = response.text.trim();
    return JSON.parse(jsonStr) as AIBuildSuggestionsResponse;

  } catch (error) {
    console.error("L·ªói khi t·∫°o g·ª£i √Ω c·∫•u h√¨nh PC:", error);
    throw new Error("Kh√¥ng th·ªÉ nh·∫≠n g·ª£i √Ω t·ª´ AI. Vui l√≤ng th·ª≠ l·∫°i sau.");
  }
};


export const generateTextWithGoogleSearch = async (
  prompt: string
): Promise<{ text: string; groundingChunks?: GroundingChunk[] }> => {
  const client = getAiClient(); 
  if (!client) {
      throw new Error(Constants.API_KEY_ERROR_MESSAGE);
  }
  try {
    const response: GenerateContentResponse = await client.models.generateContent({
      model: CHAT_MODEL_NAME, 
      contents: prompt,
      config: {
        tools: [{ googleSearch: {} }],
      },
    });
    const groundingMetadata = response.candidates?.[0]?.groundingMetadata;
    return {
      text: response.text,
      groundingChunks: groundingMetadata?.groundingChunks as GroundingChunk[] || undefined
    };
  } catch (error) {
    console.error("Error generating text with Google Search:", error);
    throw error;
  }
};

export const fetchLatestTechNews = async (): Promise<Partial<Article>[]> => {
    const client = getAiClient();
    if (!client) {
        throw new Error(Constants.API_KEY_ERROR_MESSAGE);
    }
    // FIX: Import and use ARTICLE_CATEGORIES from constants
    const prompt = `L√†m m·ªôt bi√™n t·∫≠p vi√™n tin t·ª©c c√¥ng ngh·ªá t·∫°i Vi·ªát Nam. S·ª≠ d·ª•ng Google Search ƒë·ªÉ t√¨m 3 tin t·ª©c c√¥ng ngh·ªá m·ªõi v√† th√∫ v·ªã nh·∫•t trong v√†i ng√†y qua (∆∞u ti√™n tin li√™n quan ƒë·∫øn PC, ph·∫ßn c·ª©ng, AI). 
    ƒê·ªëi v·ªõi m·ªói tin t·ª©c, h√£y cung c·∫•p m·ªôt ti√™u ƒë·ªÅ ti·∫øng Vi·ªát h·∫•p d·∫´n, m·ªôt b·∫£n t√≥m t·∫Øt (summary) ti·∫øng Vi·ªát kho·∫£ng 2-3 c√¢u, m·ªôt n·ªôi dung chi ti·∫øt (content) ti·∫øng Vi·ªát ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng b·∫±ng Markdown, m·ªôt danh m·ª•c (category) t·ª´ danh s√°ch sau: [${Constants.ARTICLE_CATEGORIES.join(', ')}], v√† m·ªôt c·ª•m t·ª´ kh√≥a t√¨m ki·∫øm h√¨nh ·∫£nh b·∫±ng ti·∫øng Anh (imageSearchQuery) ng·∫Øn g·ªçn, ph√π h·ª£p v·ªõi n·ªôi dung.
    Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng m·ªôt m·∫£ng JSON.`;

    try {
        const response = await client.models.generateContent({
            model: CHAT_MODEL_NAME,
            contents: prompt,
            config: {
                tools: [{ googleSearch: {} }],
            }
        });

        let jsonStr = response.text.trim();
        // Clean up markdown fences if they exist
        const fenceRegex = /^\`\`\`(\w*)?\s*\n?(.*?)\n?\s*\`\`\`$/s;
        const match = jsonStr.match(fenceRegex);
        if (match && match[2]) {
            jsonStr = match[2].trim();
        }
        
        return JSON.parse(jsonStr) as Partial<Article>[];

    } catch (error) {
        console.error("Error fetching latest tech news:", error);
        throw new Error("Kh√¥ng th·ªÉ l·∫•y tin t·ª©c m·ªõi nh·∫•t t·ª´ AI. Vui l√≤ng ki·ªÉm tra l·∫°i API Key v√† th·ª≠ l·∫°i.");
    }
};

export const sendMessageWithImage = async (
  message: string,
  base64Data: string,
  mimeType: string,
  currentChatInstance?: Chat
): Promise<AsyncIterable<GenerateContentResponse>> => {
    const chatToUse = currentChatInstance || chatSessionInstance;
    if (!chatToUse) {
        throw new Error("Chat not initialized. Call startChat first.");
    }

    const imagePart: Part = {
        inlineData: {
            data: base64Data,
            mimeType: mimeType
        }
    };

    const textPart: Part = {
        text: message
    };
    
    try {
        const result = await chatToUse.sendMessageStream({
            // FIX: Ensure 'message' property holds an object with a 'parts' array when sending multi-modal content.
            // This corrects the type error where a string was being assigned to a property expecting a complex object.
            message: { parts: [textPart, imagePart] }
        });
        return result;
    } catch (error) {
        console.error("Error sending message with image to Gemini:", error);
        throw error;
    }
};

const geminiService = {
    startChat,
    sendMessageToChatStream,
    sendMessageWithImage,
    generatePCBuildRecommendation,
    generateTextWithGoogleSearch,
    fetchLatestTechNews,
    generatePCBuildSuggestions,
};

export default geminiService;
